{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d23e3a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/bitnami/python/lib/python3.8/site-packages (3.2.0)\n",
      "Requirement already satisfied: py4j==0.10.9.2 in /opt/bitnami/python/lib/python3.8/site-packages (from pyspark) (0.10.9.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: pandas in /opt/bitnami/python/lib/python3.8/site-packages (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/bitnami/python/lib/python3.8/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/bitnami/python/lib/python3.8/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/bitnami/python/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/bitnami/python/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pyspark\n",
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbb54c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.amazonaws#aws-java-sdk-s3 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "org.apache.spark#spark-avro_2.12 added as a dependency\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      "org.postgresql#postgresql added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-fd6434b0-8870-4d46-8d12-e789fce1450e;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.amazonaws#aws-java-sdk-s3;1.12.95 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-kms;1.12.95 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-core;1.12.95 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound software.amazon.ion#ion-java;1.0.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.12.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.12.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.12.3 in central\n",
      "\tfound com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.12.3 in central\n",
      "\tfound joda-time#joda-time;2.8.1 in central\n",
      "\tfound com.amazonaws#jmespath-java;1.12.95 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.2.0 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.375 in central\n",
      "\tfound org.apache.spark#spark-avro_2.12;2.4.4 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      "\tfound org.postgresql#postgresql;42.2.18 in central\n",
      "\tfound org.checkerframework#checker-qual;3.5.0 in central\n",
      ":: resolution report :: resolve 736ms :: artifacts dl 21ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.375 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-core;1.12.95 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-kms;1.12.95 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-s3;1.12.95 from central in [default]\n",
      "\tcom.amazonaws#jmespath-java;1.12.95 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.12.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.12.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.12.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.12.3 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tjoda-time#joda-time;2.8.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.2.0 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.apache.spark#spark-avro_2.12;2.4.4 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.5.0 from central in [default]\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]\n",
      "\torg.postgresql#postgresql;42.2.18 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\tsoftware.amazon.ion#ion-java;1.0.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcommons-logging#commons-logging;1.2 by [commons-logging#commons-logging;1.1.3] in [default]\n",
      "\tcommons-codec#commons-codec;1.11 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   26  |   0   |   0   |   2   ||   24  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-fd6434b0-8870-4d46-8d12-e789fce1450e\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 24 already retrieved (0kB/17ms)\n",
      "21/12/26 14:42:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://420a9e457ac4:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://172.1.0.2:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>dw-dim_date</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fea02012760>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "packages = [\n",
    "    \"com.amazonaws:aws-java-sdk-s3:1.12.95\",\n",
    "    \"org.apache.hadoop:hadoop-aws:3.2.0\",\n",
    "    \"org.apache.spark:spark-avro_2.12:2.4.4\",\n",
    "    \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\",\n",
    "    \"org.postgresql:postgresql:42.2.18\"\n",
    "\n",
    "]\n",
    "\n",
    "spark = SparkSession.builder.appName(\"dw-dim_date\")\\\n",
    "    .master('spark://172.1.0.2:7077')\\\n",
    "    .config(\"spark.jars.packages\", \",\".join(packages))\\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.multipart.size\", 104857600)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3dd91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "\n",
    "festival_dict = {'2022-01-01': '2022新曆新年',\n",
    "                 '2022-02-01': '農曆年初一',\n",
    "                 '2022-02-02': '農曆年初二',\n",
    "                 '2022-02-03': '農曆年初三',\n",
    "                 '2022-02-14': '情人節',\n",
    "                 '2022-02-15': '元宵節',\n",
    "                 '2022-03-14': '白色情人節',\n",
    "                 '2022-04-18': '復活節',\n",
    "                 '2022-05-08': '母親節',\n",
    "                 '2022-06-03': '端午節',\n",
    "                 '2022-06-19': '父親節',\n",
    "                 '2022-08-04': '七夕節',\n",
    "                 '2022-09-10': '中秋節',\n",
    "                 '2022-10-31': '萬聖節',\n",
    "                 '2022-11-24': '感恩節',\n",
    "                 '2022-12-25': '聖誕節',\n",
    "                 '2023-01-01': '2023新曆新年',\n",
    "                 '2023-01-22': '農曆年初一',\n",
    "                 '2023-01-23': '農曆年初二',\n",
    "                 '2023-01-24': '農曆年初三',\n",
    "                 '2023-02-05': '元宵節',\n",
    "                 '2023-02-14': '情人節','2023-03-14': '白色情人節',\n",
    "                 '2023-04-10': '復活節',\n",
    "                 '2023-05-14': '母親節',\n",
    "                 '2023-06-19': '父親節',\n",
    "                 '2023-06-22': '端午節',\n",
    "                 '2023-08-22': '七夕節',\n",
    "                 '2023-09-29': '中秋節',\n",
    "                 '2023-10-31': '萬聖節',\n",
    "                 '2023-11-23': '感恩節',\n",
    "                 '2023-12-25': '聖誕節'}\n",
    "public_holiday_list = ['2022-01-01',\n",
    "                       '2022-01-01',\n",
    "                       '2022-02-02',\n",
    "                       '2022-03-03',\n",
    "                       '2022-05-05',\n",
    "                       '2022-15-15',\n",
    "                       '2022-16-16',\n",
    "                       '2022-18-18',\n",
    "                       '2022-02-02',\n",
    "                       '2022-09-09',\n",
    "                       '2022-03-03',\n",
    "                       '2022-01-01',\n",
    "                       '2022-12-12',\n",
    "                       '2022-01-01',\n",
    "                       '2022-04-04',\n",
    "                       '2022-26-26',\n",
    "                       '2022-27-27']\n",
    "good_days_list = ['2022-01-05',\n",
    "                  '2022-01-16',\n",
    "                  '2022-01-19',\n",
    "                  '2022-01-22',\n",
    "                  '2022-01-28',\n",
    "                  '2022-01-31',\n",
    "                  '2022-02-04',\n",
    "                  '2022-02-11',\n",
    "                  '2022-02-19',\n",
    "                  '2022-02-23',\n",
    "                  '2022-03-04',\n",
    "                  '2022-03-07',\n",
    "                  '2022-03-19',\n",
    "                  '2022-03-24',\n",
    "                  '2022-03-30',\n",
    "                  '2022-04-03',\n",
    "                  '2022-04-09',\n",
    "                  '2022-04-19',\n",
    "                  '2022-04-23',\n",
    "                  '2022-05-05',\n",
    "                  '2022-05-08',\n",
    "                  '2022-05-11',\n",
    "                  '2022-05-15',\n",
    "                  '2022-05-20',\n",
    "                  '2022-05-26',\n",
    "                  '2022-06-01',\n",
    "                  '2022-06-04',\n",
    "                  '2022-06-12',\n",
    "                  '2022-06-14',\n",
    "                  '2022-06-20',\n",
    "                  '2022-06-23',\n",
    "                  '2022-07-05',\n",
    "                  '2022-07-07',\n",
    "                  '2022-07-12',\n",
    "                  '2022-07-15',\n",
    "                  '2022-07-18',\n",
    "                  '2022-07-20',\n",
    "                  '2022-07-25',\n",
    "                  '2022-07-31',\n",
    "                  '2022-08-06',\n",
    "                  '2022-08-09',\n",
    "                  '2022-08-11',\n",
    "                  '2022-08-18',\n",
    "                  '2022-08-21',\n",
    "                  '2022-08-31',\n",
    "                  '2022-09-09',\n",
    "                  '2022-09-14',\n",
    "                  '2022-09-21',\n",
    "                  '2022-09-26',\n",
    "                  '2022-09-30',\n",
    "                  '2022-10-06',\n",
    "                  '2022-10-10',\n",
    "                  '2022-10-17',\n",
    "                  '2022-10-24',\n",
    "                  '2022-11-01',\n",
    "                  '2022-11-03',\n",
    "                  '2022-11-07',\n",
    "                  '2022-11-19',\n",
    "                  '2022-11-25',\n",
    "                  '2022-12-03',\n",
    "                  '2022-12-14',\n",
    "                  '2022-12-26', ]\n",
    "wedding_expo_list = ['2022-02-11',\n",
    "                     '2022-02-12',\n",
    "                     '2022-02-13',\n",
    "                     '2022-06-03',\n",
    "                     '2022-06-04',\n",
    "                     '2022-06-05',\n",
    "                     '2022-08-26',\n",
    "                     '2022-08-27',\n",
    "                     '2022-08-28',\n",
    "                     '2022-12-09',\n",
    "                     '2022-12-10',\n",
    "                     '2022-12-11', ]\n",
    "\n",
    "\n",
    "dim_date_list = []\n",
    "new_year = datetime(2022, 1, 1, 0, 0, 0, 0)\n",
    "for num in range(365*2):\n",
    "    date = (new_year + timedelta(days=num))\n",
    "    if date.strftime(\"%Y-%m-%d\") in festival_dict:\n",
    "        festival = festival_dict[date.strftime(\"%Y-%m-%d\")]\n",
    "    date_row = {\n",
    "        \"full_date\": date,\n",
    "        \"year\": int(date.strftime('%Y')),\n",
    "        \"month\": int(date.strftime('%m')),\n",
    "        \"day\": int(date.strftime('%d')),\n",
    "        \"quarter\": int((date.month-1)/3)+1,\n",
    "        \"day_of_week_num\": date.weekday(),\n",
    "        \"day_of_week_eng_abbr\": date.strftime('%a'),\n",
    "        \"festival\": festival_dict[date.strftime(\n",
    "            \"%Y-%m-%d\")] if date.strftime(\"%Y-%m-%d\") in festival_dict else False,\n",
    "        \"is_good_days\": True if date in good_days_list else False,\n",
    "        \"is_weekend\": True if (date.weekday() == 5) | (date.weekday() == 6) else False,\n",
    "        \"is_public_holiday\": True if (date.weekday() == 6) | (date in public_holiday_list) else False,\n",
    "        \"is_wedding_expo\": True if date in wedding_expo_list else False\n",
    "    }\n",
    "    dim_date_list.append(date_row)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df = pd.DataFrame(dim_date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90a2c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import *\n",
    "# Auxiliar functions\n",
    "def equivalent_type(f):\n",
    "    if f == 'datetime64[ns]': return TimestampType()\n",
    "    elif f == 'int64': return LongType()\n",
    "    elif f == 'int32': return IntegerType()\n",
    "    elif f == 'float64': return FloatType()\n",
    "    else: return StringType()\n",
    "\n",
    "def define_structure(string, format_type):\n",
    "    try: typo = equivalent_type(format_type)\n",
    "    except: typo = StringType()\n",
    "    return StructField(string, typo)\n",
    "\n",
    "# Given pandas dataframe, it will return a spark's dataframe.\n",
    "def pandas_to_spark(pandas_df):\n",
    "    columns = list(pandas_df.columns)\n",
    "    types = list(pandas_df.dtypes)\n",
    "    struct_list = []\n",
    "    for column, typo in zip(columns, types): \n",
    "      struct_list.append(define_structure(column, typo))\n",
    "    p_schema = StructType(struct_list)\n",
    "    return spark.createDataFrame(pandas_df, p_schema)\n",
    "\n",
    "spark_df = pandas_to_spark(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc84fce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "RDS_DB=\"wedding\"\n",
    "RDS_USERNAME=\"postgres\"\n",
    "RDS_PASSWORD=\"postgres\"\n",
    "RDS_HOST=\"final-project-data-warehouse.cit8sojr7959.ap-southeast-1.rds.amazonaws.com\"\n",
    "\n",
    "spark_df.write.format('jdbc')\\\n",
    "    .option(\"truncate\", \"true\")\\\n",
    "    .option('url', \"jdbc:postgresql://{}/{}\".format(RDS_HOST, RDS_DB))\\\n",
    "    .option('dbtable', 'dim_date')\\\n",
    "    .option('user', RDS_USERNAME)\\\n",
    "    .option('password', RDS_PASSWORD)\\\n",
    "    .option('driver', 'org.postgresql.Driver')\\\n",
    "    .mode('overwrite')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb9acae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
